{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The home of bohra","text":"<p>Comprehensive sequence characterisation for microbial genomics</p>"},{"location":"#introduction","title":"Introduction","text":"<p><code>bohra</code> is microbial genomics pipeline, designed predominantly for use in public health, but may also be useful in research settings. It leverages existing high quality bioinformatics tools, to provide users with an easily accessible report of comprehensive analysis results of bacterial sequence data to for characterisation of single samples or for outbreak investigations or population studies. </p> <ol> <li>Quality assessment of the input data</li> <li>Speciation and appropriate in silico serotyping (where applicable).</li> <li>MLST</li> <li>Species relevant recovery of AMR mechanisms and inference of genomic AST/DST were available (S. enterica and M. tuberulosis).</li> <li>Plasmid information</li> <li>Comparative analysis using a reference-free or reference-based appproaches.</li> <li>Pangenome analysis.</li> </ol> <p>The pipeline is designed to be flexible and modular, allowing for inputs from paired end fastq or assemblies, with direct support for ONT coming soon.</p> <p>Stand alone html reports are generated for easy sharing and visualisation of the results.</p>"},{"location":"#workflows","title":"Workflows","text":"<p><code>bohra</code> is a flexible pipeline and allows users to customise the workflows used. Below is an overview of each workflow. More detail on tools and options for each workflow can be found here and here. Further explanations and detailed guides can be found here</p> <p>basic</p> <p>This workflow will run on fastq and/or fasta (depending user supplied input) and is the first step in all other workflows implmented by <code>bohra</code>. It can also be used alone as a simply quality control workflow. <pre><code>flowchart LR\nsequence --&gt; sequence_assessment --&gt; report\nsequence --&gt; speciation --&gt; report</code></pre></p> <p>assembly</p> <p>This workflow will simple generate assemblies from paired-end fastq, run basic genome annotation with <code>prokka</code> and assess the quality of both the input reads and the resulting assemblies. This workflow forms the basis for amr, typing and pangenome analysis.</p> <pre><code>flowchart LR\nfastq --&gt; assembly --&gt; annotation --&gt; sequence_assessment\nassembly --&gt; speciation\nfastq --&gt; sequence_assessment --&gt; report\nfastq --&gt; speciation --&gt; report\n</code></pre> <p>amr and typing</p> <p>This workflow will use user supplied species or the species detected in the sequence to determine the appropriate typing and AMR pipeline to use. Additional inferrence of genomic DST/AST will be undertaken for S. enterica and M. tuberculosis.</p> <p>If assembly is required and fastq are used as input - the assembly workflow will be triggered. </p> <p>Note that for AMR and gDST in M. tuberculosis paired-end fastq are required. We recommend to use the <code>bohra run tb</code> workflow for M. tuberculosis.</p> <pre><code>flowchart LR\nfastq --&gt; assembly --&gt; annotation --&gt; sequence_assessment\nassembly --&gt; typing\nassembly --&gt; AMR\nassembly --&gt; speciation\nspeciation --&gt; typing --&gt; report\nspeciation --&gt; AMR --&gt; report\nfastq --&gt; sequence_assessment --&gt; report\nfastq --&gt; speciation --&gt; report</code></pre> <p>comparative analysis</p> <p>This workflow undertakes a comparative anaysis of all the sequences included in the analysis. You can use reference based alignments with <code>snippy</code> or you can use reference free approaches with <code>mash</code> and <code>ska2</code>. </p> <pre><code>flowchart LR\nsequence --&gt; sequence_assessment --&gt; report\nsequence --&gt; speciation --&gt; report\nsequence --&gt; variant_detection --&gt; distances --&gt; cluster --&gt; report\nvariant_detection --&gt; alignment --&gt; tree_generation --&gt; report</code></pre> <p>full</p> <p>The full workflow includes all the workflows outlined above with the addition of pangenome analysis using <code>panaroo</code>.</p> <pre><code>flowchart LR\nfastq --&gt; assembly --&gt; annotation --&gt; sequence_assessment\nassembly --&gt; speciation\nfastq --&gt; sequence_assessment --&gt; report\nfastq --&gt; speciation --&gt; report\nspeciation --&gt; typing --&gt; report\nassembly --&gt; typing\nspeciation --&gt; AMR --&gt; report\nassembly --&gt; AMR\nassembly --&gt; pangenome --&gt; report\nassembly -- \"only possible with reference free\" --&gt; variant_detection\nfastq --&gt; variant_detection --&gt; distances --&gt; cluster --&gt; report\nvariant_detection --&gt; alignment --&gt; tree_generation --&gt; report</code></pre> <p>tb</p> <p><code>bohra</code> now has a M. tuberulosis specific workflow, which does not run MLST or other assembly based tools. And undertakes M. tuberculosis relevant gDST. It uses the H37rV reference genome, masking repetitive sites and <code>tbtAMR</code> for generation of an inferred antibiogram. <pre><code>flowchart LR\nfastq --&gt; sequence_assessment --&gt; report\nfastq --&gt; speciation --&gt; report\nspeciation --&gt; lineage --&gt; report\nfastq --&gt; AMR --&gt; report\nfastq --&gt; variant_detection --&gt; distances --&gt; cluster --&gt; report\nvariant_detection --&gt; alignment --&gt; tree_generation --&gt; report</code></pre></p>"},{"location":"#etymology","title":"Etymology","text":"<p>The name 'bohra', is the name of an exinct species of tree kangaroo that lived on the Nullarbor plain in Australia was chosen to reflect the fact that it was originally developed to used to build trees, relies on snippy (named for a very famous kangaroo) and was inspired by nullarbor.</p>"},{"location":"installation/","title":"Installation","text":"<p>Note the following instructions are for pre-release installation for <code>bohra</code> version 3</p> <p><code>bohra</code> is a large pipeline with many dependencies, including databases required for speciation. Currently <code>bohra</code> is only available for installation with <code>conda</code>.</p>"},{"location":"installation/#create-the-environment","title":"Create the environment","text":""},{"location":"installation/#1-install-conda","title":"1. Install conda","text":"<p>If you do not already have <code>conda</code> installed, you can check out the documentation here. We recommend you install <code>miniconda</code></p> <p>Below are instructions to install <code>miniconda</code> on a linux machine, however there are other distributions for Windows and MacOS here</p> <ol> <li>Download and install miniconda </li> </ol> <p><pre><code>mkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm ~/miniconda3/miniconda.sh\n</code></pre> 2. Restart your terminal and then </p> <pre><code>source ~/miniconda3/bin/activate\n</code></pre> <ol> <li>Initialise <code>conda</code></li> </ol> <pre><code>conda init --all\n</code></pre>"},{"location":"installation/#2-setup-the-bohra-environment-and-install-the-pipeline-co-ordinator","title":"2. Setup the <code>bohra</code> environment and install the pipeline co-ordinator","text":"<ol> <li>You can download the <code>environment.yml</code> file here. Please note that on the last line you may need to update the path to where your conda environments are stored. For example if you installed <code>miniconda</code> as above you should chnage this to line to:</li> </ol> <p><pre><code>prefix: ~/miniconda/envs/bohra-3pr\n</code></pre> 2. Create the environment </p> <pre><code>conda env create -f environment.yml\n</code></pre> <ol> <li>Install the <code>bohra</code> co-ordinator</li> </ol> <p><pre><code>pip3 install git+https://github.com/MDU-PHL/bohra.git@rethink_structure\n</code></pre> 4. Test this has worked as expected <pre><code>bohra --help\n</code></pre> Should result in </p> <pre><code>Usage: bohra [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --version  Show the version and exit.\n  --help     Show this message and exit.\n\nCommands:\n  check           Check that dependencies are installed correctly.\n  generate-input  Generare input files for the Bohra pipeline.\n  install-deps    Install dependencies for Bohra - Highly recommended to...\n  run             Run the Bohra pipeline.\n  test            Check that bohra is installed correctly\n</code></pre>"},{"location":"installation/#3-install-dependencies-and-setup-environment-variables","title":"3. Install dependencies and setup environment variables","text":"<p>It is highly recommended that you allow <code>bohra</code> to setup the required dependencies for the pipeline. </p> <p>This step will setup conda environments in your <code>~/.conda</code> or <code>~/.miniconda3</code> (depending on how you have configured your <code>conda</code> installation). These environments will be prefixed with the name of the environment that you have installed <code>bohra</code> into. For example if you used the <code>environment.yml</code> file in step 2 your prefix will be <code>bohra-3pr</code>. This will ensure consistency and prevent duplication of environments across a file system. </p> <p>This is also useful for public health users, were the versions of software and databases needs to be strictly controlled.</p> <p>Additionally, <code>bohra</code> depends upon either a correctly configure <code>kraken2</code> compatible database OR a <code>sylph</code> compatible database. The <code>bohra install-deps</code> command will optionally download the databases for your and also set the appropriate environment variables for you.</p> <ol> <li> <p>Activate your environment from step 2 above <pre><code>conda activate bohra-3pr\n</code></pre></p> </li> <li> <p>Run the bohra dependency installation</p> </li> </ol> <pre><code>bohra install-deps\n</code></pre> <p>The initial creation of the conda environments may take some time. Once the environments are set up, <code>bohra</code> will try to set up your database environment variables. Although this is not essential it is HIGHLY recommended for ease of running and reproducibility. </p> <p>Please be aware of the following:</p> <ul> <li> <p>If you elect to say no to setting up a <code>BOHRA_KRAKEN2_DB</code> or <code>BOHRA_SYLPH_DB</code>, you will need to provide EITHER the <code>--kraken2_db</code> OR a <code>--sylph_db</code> flag each time you run <code>bohra</code> if you wish to do speciation or use any features which depend on species (typing and AMR).</p> </li> <li> <p>If you are happy to use the <code>mlst</code> database that comes bundled with the <code>mlst</code> tool, then you can decline setting the <code>BOHRA_PUBMLST_DB</code> and <code>BOHRA_BLAST_DB</code>.</p> </li> <li> <p>If you are working in your own environments (<code>~/.conda</code> or <code>~/.miniconda</code>) you skip setting the <code>BOHRA_MOBSUITE_DB</code> environment variable. However, please note if you are setting up <code>bohra</code> in a share environment, you may run into permissions issues if <code>mobsuite</code> database requires updating at the time of running (this can happen) - so please ensure that you have a properly set up <code>mob_suite</code> database and provide this path when requested during set up.</p> </li> <li> <p>If you already have a kraken2 database and/or a sylph database you can press 'n' when asked if you want to download. If you select 'y' please make sure that you have enough storage space for the databases. Some are quite large, up to 600 GB (half-terabyte).</p> </li> </ul>"},{"location":"usage/overview/","title":"Usage overview","text":"<p>Users have the option to supply paired-end fastq (support for ONT coming soon) and/or de novo assemblies as inputs into the pipeline. </p> <ul> <li> <p>Paired-end fastq only - where you only have paired-end fastq <code>bohra</code> will generate de novo assemblies if required.</p> </li> <li> <p>de novo assemblies only - where you only have de novo assemblies <code>bohra</code> will not use a reference-based approach for comparative analysis. However, reference-free comparative tools, <code>ska2</code> and <code>mash</code> are available.</p> </li> <li> <p>Both paired-end fastq and de novo assemblies - in situations where you have de novo assemblies already generate, you can supply both sequence types to <code>bohra</code>. It will use the supplied de novo assemblies for any steps which require them, potentially saving you time.</p> </li> </ul> <p>Additionally, you can also supply the species value and any optional sample metadata that may be useful.</p>"},{"location":"usage/overview/#input-file","title":"Input file","text":"<p><code>bohra</code> requires a single tab-delimited file as input, you can find examples [here] TO ADD.</p> Column name Description Required? Isolate This is the name of the sequence or sample and will appear throughout <code>bohra</code> outputs. It must be unique. Yes r1 The path to read 1 If an assembly file is not supplied you must supply reads r2 The path to read 2 If an assembly file is not supplied you must supply reads assembly The path to the assembly for the isolate If reads are not supplied you must supply an assembly file species The expected species of the sample or 'control'. No"},{"location":"usage/overview/#species-column","title":"Species column","text":"<p>If you do not require speciation as part of the pipeline and already know the species, you can provide it here. Please note if no speciation is undertaken, <code>bohra</code> will use this value to undertake typing and AMR mechanisms/inferrence. If the species in this column is NOT accurate - unexpected results may occur. Furthermore if your analysis includes control sequences you can provide that information here (<code>control</code>) and the sequence will not be included in any comparative analysis.</p>"},{"location":"usage/overview/#annotation","title":"Annotation","text":"<p>Where you are undertaking a comparative analysis (<code>snippy</code>, <code>ska2</code>, <code>mash</code>) you may also provide additional columns of relevant metadata in your input file. <code>bohra</code> will do data validation on these columns - that is up to the user. But any additional metadata provided will be visible on the tree provided in the report file.</p>"},{"location":"usage/overview/#bohra-can-generate-the-input-file-for-you","title":"<code>bohra</code> can generate the input file for you","text":"<p>If you have </p> <ul> <li>A table with a list of isolates and othe data (species or other metadata) (column 'Isolate' must be included) </li> </ul> <p>AND/OR</p> <ul> <li>Paths to your reads and/or contigs</li> </ul> <p><code>bohra</code> can generate the input file for you. </p> <p><pre><code>bohra generate-input --isolate_ids &lt;table_name&gt;.tsv --reads /path/to/reads --contigs /path/to/contigs\n</code></pre> This will generate a file called <code>bohra_input.tsv</code> which you can use as input into <code>bohra</code>.</p> <p>Note that on large file systems this may take a while</p>"},{"location":"usage/overview/#speciation","title":"Speciation","text":"<p>By default <code>bohra</code> will use <code>sylph</code> for speciation as it is quite quick and the database is relatively small, making it easier to install. However, this is ONLY available where your input are fastq files (as per <code>sylph</code> guidance). If you require speciation from assemblies to be undertaken, you will need to use <code>kraken2</code> as your speciation tool.</p>"},{"location":"usage/overview/#a-note-on-databases","title":"A note on databases","text":"<p>Many bioinformatics tools require the use of a database or data collection. Where possible and appropriate, <code>bohra</code> utilises the databases that come packaged with the tools being used in order to ensure expected behaviour and consistency. However, there are cases were the user will need to supply a database path. </p> <ul> <li> <p><code>kraken2</code> - these databases are very large and not easily packaged for distribution with software. So the user will either need to have existing databases available or download them as part of the setup of <code>bohra</code>. This information is here</p> </li> <li> <p><code>sylph</code> - like the kraken2 databases this is a fairly large collection and needs to either already be available on the system or downloaded as part of the setup for <code>bohra</code>, as detailed here</p> </li> <li> <p><code>mlst</code> comes packaged with a collection of profiles and is ready to use. However, due to changes in licensing, the most up to date profiles cannot be included. As such if you have available to you a current mlst database that is configured for use with <code>mlst</code> you can set the <code>BOHRA_PUBMLST_DB</code> and <code>BOHRA_BLAST_DB</code> environment variables as part of the setup of <code>bohra</code>, as described here</p> </li> </ul>"},{"location":"usage/running_bohra/","title":"Running <code>bohra</code>","text":"<p><code>bohra</code> has 6 pipelines to choose from</p> <ol> <li><code>basic</code></li> <li><code>assemble</code></li> <li><code>amr_typing</code></li> <li><code>comparative</code></li> <li><code>full</code></li> <li><code>tb</code></li> </ol> <p>You can see available pipelines <pre><code>bohra run  --help\n</code></pre> and help for each pipeline</p> <p><pre><code>bohra run &lt;pipeline&gt; --help\n</code></pre> For any pipeline you can elect to run speciation using <code>--speciation sylph</code> or <code>--speciation kraken2</code> or you can turn off speciation by using <code>--speciation none</code>.</p>"},{"location":"usage/running_bohra/#genome-characterisation-pipelines","title":"Genome characterisation pipelines","text":"<p>These first three pipelines will generate single sample results, such as sequence metrics, typing and recovery of AMR mechanisms. These pipelines can be run on a variety of species in the same run, ie for quality control purposes or where only sample level results are required.</p>"},{"location":"usage/running_bohra/#basic","title":"basic","text":"<p>This pipeline is a basic sequence assessment pipeline. It can be run as a standalone to assess your sequence data, but is also run as part of all other pipelines.</p> <p><pre><code>bohra run basic -i input_file.tsv -j my_basic_pipeline\n</code></pre> where - <code>-i/--input_file</code> is a tab-delimited file formatted as described here - <code>-j/--job_id</code> is the name of your run. This value will appear on your report.</p>"},{"location":"usage/running_bohra/#assemble","title":"assemble","text":"<p>This pipeline should be used if you would like to generate de novo assemblies from paired-end reads. You can choose from <code>spades</code>, <code>skesa</code>, <code>shovill + skesa</code> or <code>shovill + spades</code> (default)</p> <p><pre><code>bohra run assemble -i input_file.tsv -j my_assembly_pipeline -a shovill_skesa\n</code></pre> where - <code>-i/--input_file</code> is a tab-delimited file formatted as described here - <code>-j/--job_id</code> is the name of your run. This value will appear on your report. - <code>-a/--assembler</code> is the assembler to use (ONT coming soon)</p>"},{"location":"usage/running_bohra/#amr_typing","title":"amr_typing","text":"<p>This pipeline will use <code>abritamr</code> for AMR mechanism detection and undertake species appropriate serotyping. Please note that if you do not supply a species and set <code>--speciation none</code> there will be no species specific AMR or serotyping done. You can provide paired-end fastq and/or assemblies as input for this pipeline. If only paired-end fastq supplied, assembly will be run to generata appropriate inputs for <code>abritamr</code> and serotyping. If you would like to use a an assembly combination different from the default you will need to specify</p> <ol> <li>where inputs are only (or mostly paired-end fastq) and you want to use a different assembler to the default of <code>shovill + spades</code>. <pre><code>bohra run amr_typing -i input_file.tsv -j my_typing_pipeline -a shovill_skesa\n</code></pre></li> <li>where inputs are assemblies (or you are happy to stick with <code>shovill + spades</code> ) <pre><code>bohra run amr_typing -i input_file.tsv -j my_typing_pipeline\n</code></pre></li> </ol>"},{"location":"usage/running_bohra/#comparative-pipelines","title":"Comparative pipelines","text":"<p>These are pipelines where dataset wide comparasions are made. For example species wide phylogenetic analysis, outbreak investigations or other investigations of the relationships between sequences in a dataset. Where you have included mixed species, please be aware you may get unexpected and frankly wrong interpretations.</p> <p>All comparative pipelines have the option to cluster the distances using a heirarchical approach. You can specifiy the algorithm with <code>--cluster_method</code> (choose from <code>single</code>, <code>average</code>, <code>complete</code>, <code>centroid</code>, <code>median</code>, <code>ward</code>, <code>weighted</code>), with <code>single</code> being the default setting. You can also choose the thresholds that you want to use as a comma separate list with <code>--cluster_threshold</code> (not that the algorithms use a <code>&lt;</code> so if you provide a theshold of 10 - the cluster will actually defined at <code>&lt;= 9</code> ).</p>"},{"location":"usage/running_bohra/#comparative","title":"comparative","text":"<p>This pipeline invloves undertaking comparisons within a dataset. Please take note - it will not run any assembly based tools, like MLST or AMR. If these are required use the <code>full</code> pipeline. There are three tools available in <code>bohra</code> that can be used for this purpose 1. <code>snippy</code> (default) - a reference based approach, detecting SNPS compared to a reference genome. This option can ONLY take paired-end fastq files as input and requires the provision of a reference genome. 2. <code>ska2</code> - this is a reference free approach, inferring SNPS based on splits in kmers. You can use paired-end fastq and/or de novo assemblies as input. 3. <code>mash</code> - this is a quick reference free approach which allows for approximation of genetic distances between sequences. Like <code>ska2</code> you can provide paired-end fastq and/or de novo assemblies as input.</p> <p>Further customisation includes selection of the data which is used to generate the tree (for <code>snippy</code> and <code>ska2</code>)</p> <ol> <li>distances - you can generate a distance based tree, where the branch lengths are simply the SNP distances between sequences</li> <li>alignment - this will generate a maximum liklihood phylogentic tree, using the GTR model of phylogenetic inference.</li> </ol> <p>Additionally - you can select the tree builder to use. <code>VeryFastTree</code> is the default tree builder - as it is very quick. But if required you can also use <code>IQtree</code>.</p> <ol> <li><code>IQtree</code></li> <li><code>VeryFastTree</code> (default)</li> </ol> <p>For example</p> <p>snippy (alignment and iqtree) and cluster at a threshold of &lt;= 5 and &lt;= 25 <pre><code>bohra run comparative -i input_file.tsv -j my_snippy_pipeline -ref &lt;path_to_reference.fa(gbk)&gt; --tree_builder iqtree --cluster_threshold 6,26\n</code></pre> ska2 (distance and veryfastree) and cluster at a threshold of &lt;= 5 and &lt;= 25, using complete linkage <pre><code>bohra run comparative -i input_file.tsv -j my_ska2_pipeline --comparative_tool ska2 --cluster_method complete --cluster_threshold 6,26\n</code></pre></p>"},{"location":"usage/running_bohra/#full","title":"full","text":"<p>Like the <code>comparative</code> pipeline, you can select the comparative tool, tree builder, cluster methods, and thresholds. In addition, this pipeline will undertake the assembly, amr and typing described above and additional pangenome analysis.</p> <p>For example</p> <pre><code>bohra run full -i input_file.tsv -j my_full_pipeline -ref &lt;path_to_reference.fa(gbk)&gt; --tree_builder iqtree --cluster_threshold 6,26\n</code></pre>"},{"location":"usage/running_bohra/#tb","title":"tb","text":"<p>The <code>tb</code> pipeline will run tools specific for M. tuberculosis, using <code>tbtAMR</code> (WHO v2 catalogue) for inferrence of resistance and the H37rV reference genome and mask</p> <pre><code>bohra tb -i input_file.tsv -j my_tb_pipeline\n</code></pre>"}]}